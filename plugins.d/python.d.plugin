#!/usr/bin/env bash
'''':; exec "$(command -v python || command -v python3 || command -v python2 ||
echo "ERROR python IS NOT AVAILABLE IN THIS SYSTEM")" "$0" "$@" # '''

# -*- coding: utf-8 -*-
# Description:
# Author: Pawel Krupa (paulfantom)
# Author: Ilya Mashchenko (l2isbad)
# SPDX-License-Identifier: GPL-3.0+

import gc
import os
import sys
import re
import threading
import multiprocessing

from collections import namedtuple
from time import sleep


PLUGINS_DIR = os.path.abspath(os.getenv('NETDATA_PLUGINS_DIR', os.path.dirname(__file__)) + '/../python.d') + '/'
PYTHOND_MODULES_DIR = os.path.join(PLUGINS_DIR, "python_modules")
PYTHOND_CONFIG_DIR = os.getenv('NETDATA_CONFIG_DIR', os.path.dirname(__file__) + '/../../../../etc/netdata') + '/'
PLUGINS_CONFIG_DIR = PYTHOND_CONFIG_DIR + 'python.d/'

sys.path.append(PYTHOND_MODULES_DIR)

from bases.loaders import safe_load_module, safe_load_config
from bases.loggers import Logger

try:
    from collections import OrderedDict
except ImportError:
    from third_party.ordereddict import OrderedDict


# FIXME
OBSOLETED_PLUGINS = [
    'apache_cache',  # replaced by web_log
    'gunicorn_log',  # replaced by web_log
    'nginx_log',     # replaced by web_log
]

PLUGINS_SUFFIX = '.chart.py'

# All modules from plugins directory (*.chart.py)
ALL_PLUGINS = [
    m[:-len(PLUGINS_SUFFIX)] for m in sorted(os.listdir(PLUGINS_DIR))
    if m.endswith(PLUGINS_SUFFIX) and m[:-len(PLUGINS_SUFFIX)] not in OBSOLETED_PLUGINS
]

JOB_BASE_CONF = {
    'update_every': os.getenv('NETDATA_UPDATE_EVERY', 1),
    'retries': 60,
    'priority': 60000,
    'autodetection_retry': 0,
    'chart_cleanup': 10,
    'name': str(),
}

PYTHOND_BASE_CONF = {
        'enabled': True,
        'default_run': True,
        'gc_run': True,
        'gc_interval': 300,
}


def parse_cmd():
    class ParsedCmd:
        """

        """
        def __init__(self):
            self.debug = False
            self.trace = False
            self.update_every = 1
            self.plugins = ALL_PLUGINS

    parsed = ParsedCmd()

    cmd = sys.argv[:][1:]

    if cmd and cmd[0].isdigit():
        parsed.update_every = int(cmd.pop(0))

    if 'debug' in cmd:
        parsed.debug = True
        cmd.remove('debug')

    if 'trace' in cmd:
        parsed.debug = True
        cmd.remove('trace')

    if cmd:
        parsed.plugins = cmd

    return parsed


CMD = parse_cmd()


def load_config(path, name):
    """

    :param path:
    :param name:
    :return:
    """
    return safe_load_config('{0}{1}.conf'.format(path, name))


def load_module(module_name):
    """

    :param module_name:
    :return:
    """
    return safe_load_module(
        module_name,
        os.path.join(PLUGINS_DIR, '{0}{1}'.format(module_name, PLUGINS_SUFFIX)),
    )


Task = namedtuple(
    "Task",
    [
        "module_name",
        "is_enabled",  # explicitly enabled in python.d.conf
    ]
)

Result = namedtuple(
    "Result",
    [
        "module_name",
        "jobs_configs"
    ]
)


class JobConf(OrderedDict):
    """

    """
    def __init__(self):
        OrderedDict.__init__(self)
        self.update(JOB_BASE_CONF)

    def set_defaults_from_module(self, module):
        for k in [k for k in JOB_BASE_CONF if hasattr(module, k)]:
            self[k] = getattr(module, k)

    def set_defaults_from_config(self, module_config):
        for k in [k for k in JOB_BASE_CONF if k in module_config]:
                self[k] = module_config[k]

    def set_job_name(self, name):
        self['job_name'] = re.sub(r'\s+', '_', name)

    def set_override_name(self, name):
        self['override_name'] = re.sub(r'\s+', '_', name)

    def to_dict(self):
        d = OrderedDict()
        d.update(self)
        return d


class ModuleChecker(multiprocessing.Process, Logger):
    """

    """
    def __init__(self, task_queue, result_queue):
        multiprocessing.Process.__init__(self)
        Logger.__init__(self)
        self.job_name = 'checker'
        self.tasks = task_queue
        self.results = result_queue

    def run(self):
        """

        :return:
        """
        while True:
            task = self.tasks.get()
            if task is None:
                self.done_task()
                # shutdown marker
                self.put_result(None)
                break

            result = self.do_task(task)
            if result:
                self.put_result(result)
            self.done_task()

    def done_task(self):
        self.tasks.task_done()

    def put_result(self, result):
        self.results.put(result)

    def do_task(self, task):
        """

        :param task:
        :return:
        """

        def has_auto_detect_job(confs):
            return bool([True for conf in confs if conf['autodetection_retry'] > 0])

        module, err = load_module(task.module_name)

        # FIX ME
        if err is not None:
            return None
        else:
            pass

        # FIX ME
        if not (hasattr(module, 'Service') and callable(getattr(module, 'Service'))):
            return None

        # FIX ME
        if getattr(module, 'disabled_by_default', False):
            return None

        config, err = load_config(PLUGINS_CONFIG_DIR, task.module_name)

        # FIX ME
        if err is not None:
            pass
        else:
            pass

        configs = self.job_configs_builder(module, config or dict())

        # There is no reason to run job.check() if at least on job is "autodetect"
        if has_auto_detect_job(configs):
            return Result(module_name=module.__name__, jobs_configs=configs)

        return self.check_module(module, configs)

    def check_module(self, module, configs):
        """

        :param module:
        :param configs:
        :return:
        """
        jobs_configs = list()

        for idx, config in enumerate(configs):
            try:
                # SimpleService pops some values, so we have to copy here.
                # Shallow copy is ok.
                job = module.Service(configuration=OrderedDict(config))
            # FIX ME
            except Exception as error:
                self.error(error)
                return None

            try:
                if not job.check():
                    continue
            # FIX ME
            except Exception as error:
                self.error(error)
                return None

            # FIX ME
            jobs_configs = configs[idx:]
            break

        if not jobs_configs:
            return None

        return Result(module_name=module.__name__, jobs_configs=jobs_configs)

    @staticmethod
    def job_configs_builder(module, module_config):
        """

        :param module:
        :param module_config:
        :return:
        """

        jobs_configs = list()

        for job_name in module_config:
            if not isinstance(module_config[job_name], dict):
                continue
            conf = JobConf()
            conf.set_defaults_from_module(module)
            conf.set_defaults_from_config(module_config)
            conf.set_defaults_from_config(module_config[job_name])
            conf.set_job_name(job_name)
            conf.set_override_name(conf.pop('name'))

            jobs_configs.append(conf)

        # FIX ME
        if len(jobs_configs) == 0:
            conf = JobConf()
            conf.set_defaults_from_module(module)
            # FIX ME
            conf.update(module_config)
            conf.set_job_name(module.__name__)
            conf.set_override_name(conf.pop('name'))

            jobs_configs.append(conf)
        elif len(jobs_configs) == 1:
            conf = jobs_configs[0]
            conf.set_job_name(module.__name__)

        return [conf.to_dict() for conf in jobs_configs]


class JobThread(threading.Thread):
    """

    """
    def __init__(self, job):
        threading.Thread.__init__(self)
        self.daemon = True
        self.job = job

    def run(self):
        self.job.run()


class PythonD(Logger):
    """

    """
    def __init__(self):
        Logger.__init__(self)
        self.job_name = 'main'
        self.conf = dict(PYTHOND_BASE_CONF)
        self.runs = 0
        self.auto_detect_jobs = list()
        self.tasks = list()
        self.results = list()
        self.task_queue = multiprocessing.JoinableQueue()
        # multiprocessing.Queue().empty() can be bugged
        self.result_queue = multiprocessing.JoinableQueue()

    def shutdown(self, msg=str()):
        if msg:
            self.info(msg)
        print("FINISHED\n")
        exit(1)

    def setup(self):
        """

        :return:

        result: populated enabled_modules list (list of named tuples)
        """
        conf, err = load_config(PYTHOND_CONFIG_DIR, "python.d")

        if err is not None:
            self.error('"python.d.conf" configuration file not found. Using defaults.')
        else:
            self.conf.update(conf)

        if not self.conf['enabled']:
            self.shutdown('disabled in configuration file.')

        wrong_modules = set(CMD.plugins) - set(ALL_PLUGINS)

        if wrong_modules:
            self.shutdown('wrong modules: {0}'.format(list(wrong_modules)))

        for name in CMD.plugins:
            cond1 = self.conf['default_run'] and self.conf.get(name, True)
            cond2 = (not self.conf['default_run']) and self.conf.get(name)

            if cond1 or cond2:
                self.tasks.append(
                    Task(module_name=name, is_enabled=self.conf.get(name))
                )
            else:
                self.debug('plugin "{0}" disabled in configuration file'.format(name))
        return

    def main(self):
        """

        :return:
        """
        if not self.tasks:
            self.shutdown('No plugins to run. Exit...')

        worker = ModuleChecker(self.task_queue, self.result_queue)
        self.enqueue_tasks()
        worker.start()

        # wait until all task are processed
        self.task_queue.join()

        self.get_results()

        # cleanup
        worker.join()

        if not self.results:
            self.shutdown('No jobs to run. Exit...')

        self.launch_jobs()
        self.serve()

    def enqueue_tasks(self):
        for task in self.tasks:
            self.task_queue.put(task)
        # shutdown marker
        self.task_queue.put(None)

    def get_results(self):
        while True:
            result = self.result_queue.get()
            self.result_queue.task_done()
            if result is None:
                self.result_queue.join()
                break
            self.results.append(result)

    def launch_jobs(self):
        """

        :return:
        """
        started = dict()

        for result in self.results:
            mod_name, configs = result.module_name, result.jobs_configs
            started[mod_name] = list()

            for config in configs:

                job = self.init_job(mod_name, config)

                if job is None:
                    # skip the whole module in case of Exception in init()
                    self.error('module "{0}" skipped'.format(mod_name))
                    break

                if job.name in started[mod_name]:
                    job.info('dropped (already served by another job)')
                    continue

                checked = self.check_job(job)

                if checked is None:
                    # unhandled exception
                    continue
                elif checked:
                    started[mod_name].append(job.name)
                else:
                    # auto detected jobs counts as started
                    if config['autodetection_retry'] > 0:
                        started[mod_name].append(job.name)
                        self.auto_detect_jobs.append(job)
                    continue

                if not self.create_job(job):
                    continue

                self.start_job(job)

    def init_job(self, module_name, job_config):
        try:
            # returned from sys.path if already imported
            mod, _ = load_module(module_name)
            job = mod.Service(job_config)
        except Exception as error:
            self.error('plugin "{0}" init() unhandled exception: {1}'.format(module_name, error))
            return None
        else:
            return job

    @staticmethod
    def check_job(job):
        try:
            ok = job.check()
        except Exception as error:
            job.error('check() unhandled exception: {0}'.format(error))
            return None
        else:
            log = job.error if ok else job.info
            log('check() => [{0}]'.format('OK' if ok else 'FAIL'))
            return ok

    @staticmethod
    def create_job(job):
        try:
            ok = job.create()
        except Exception as error:
            job.error('create() unhandled exception: {0}'.format(error))
            return None
        else:
            log = job.error if ok else job.info
            log('create() => [{0}]'.format('OK' if ok else 'FAIL'))
            return ok

    @staticmethod
    def start_job(job):
        """

        :param job:
        :return:
        """
        if job.update_every < int(CMD.update_every):
            job.update_every = int(CMD.update_every)
        JobThread(job).start()

    def retry_job(self, job):
        """

        :param job:
        :return:
        """
        v = job.configuration['autodetection_retry']
        if not self.runs % v == 0:
            return False

        if self.check_job(job) and self.check_create(job):
            self.start_job(job)
            return True

        return False

    def serve(self):
        """

        :return:
        """
        while True:
            self.runs += 1

            if threading.active_count() <= 1 and not self.auto_detect_jobs:
                self.shutdown()

            sleep(1)

            if self.conf['gc_run'] and self.runs % self.conf['gc_interval'] == 0:
                v = gc.collect()
                self.debug('GC collection run result: {0}'.format(v))

            self.auto_detect_jobs = [job for job in self.auto_detect_jobs if not self.retry_job(job)]


if __name__ == '__main__':
    pythond = PythonD()

    if CMD.debug:
        pythond.logger.severity = 'DEBUG'

    if CMD.trace:
        pythond.log_traceback = True

    pythond.info('Using python {0}'.format(sys.version[2:][0]))

    pythond.setup()
    pythond.main()
